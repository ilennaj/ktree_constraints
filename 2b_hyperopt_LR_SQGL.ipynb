{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt LR SQGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fit_params.fit_functions import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from custompackage.load_architecture import *\n",
    "from custompackage.load_data import *\n",
    "from custompackage.traintestloop import *\n",
    "\n",
    "import sparselinear as sl\n",
    "import custompackage.sl_custom as slc\n",
    "\n",
    "import hyperopt as hp\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperoptimizer():\n",
    "    '''\n",
    "    - Includes objective function methods\n",
    "    - Includes run trials\n",
    "    - Includes \"while true\" loop\n",
    "    - Parameters will be: dataset, file location, types of hyperparameters optimized\n",
    "    - Activation functions: ReLU, LReLU, Sigmoid, SiLU, Swish, SQGL\n",
    "    - Learning-rate focused\n",
    "    '''\n",
    "    def __init__(self, model_type='ktree', selector=0, dataset='mnist', DIR='./results/temp/', threshold=300, Synapse=False,\n",
    "                 activation='sqgl', leak=0.01, positive=False):\n",
    "        self.model_type = model_type\n",
    "        self.selector = selector\n",
    "        self.dataset = dataset\n",
    "        self.DIR = DIR\n",
    "        self.threshold = threshold\n",
    "        self.Synapse = Synapse\n",
    "        self.activation = activation\n",
    "        self.leak = leak\n",
    "        self.positive = positive\n",
    "        \n",
    "        if self.Synapse == True:\n",
    "            self.syn_key = 'syn'\n",
    "        else:\n",
    "            self.syn_key = 'nosyn'\n",
    "            \n",
    "        if self.positive == True:\n",
    "            self.pos_key = 'pos'\n",
    "        else:\n",
    "            self.pos_key = 'posneg'\n",
    "        \n",
    "        self.space = hp.choice('a',\n",
    "                                [\n",
    "                                    {\n",
    "                                        'lr': hp.uniform('lr', 0.0001, 0.01)\n",
    "                                    }\n",
    "                                ])\n",
    "    \n",
    "    def objective(self, params):\n",
    "        \n",
    "        #Hyperparameter to be optimized\n",
    "        lr = params['lr']\n",
    "        \n",
    "        #SQGL parameters if appropriate\n",
    "\n",
    "        atten = 0.5\n",
    "        scale = 1\n",
    "        \n",
    "        # Initialize settings\n",
    "        bs = 256\n",
    "        weighting = 'paired'\n",
    "        trials = 10\n",
    "        epochs = 2000\n",
    "        trees_set = [1]\n",
    "        trees = trees_set[0]\n",
    "\n",
    "        # Load class-dataset list\n",
    "        classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "        classes = [classes[self.selector]]\n",
    "\n",
    "\n",
    "        # For each dataset enumerated from classes list\n",
    "        for j, (t1, t2, ds) in enumerate(classes):\n",
    "            print(t1, t2, ds)\n",
    "            # Load data loaders\n",
    "            trainloaders, validloaders, testloader = dataset_weighted_split_all(bs, t1, t2, weighting, trials, ds, permute=False)\n",
    "            # Initialize input size for model initialization purposes\n",
    "            input_size = trainloaders[0].dataset.tensors[0][0].shape[0]\n",
    "            # For each trial\n",
    "            # Initialize the model\n",
    "            if self.model_type == 'fcnn':\n",
    "                if self.Synapse == True:\n",
    "                    model = synapse_fcnn(Input_size=input_size, Hidden_size=trees*2, Output_size=1,\n",
    "                                         Activation=self.activation, learn=False, alpha=1, beta=1, gamma=1, \n",
    "                                         scale=scale, atten=atten, leak=self.leak).cuda()\n",
    "                else:\n",
    "                    model = simple_fcnn(Input_size=input_size, Hidden_size=trees*2, Output_size=1,\n",
    "                                         Activation=self.activation, learn=False, alpha=1, beta=1, gamma=1, \n",
    "                                         scale=scale, atten=atten, leak=self.leak).cuda()\n",
    "            else:\n",
    "                if self.Synapse == True:\n",
    "                    model = ktree_synapse(ds=ds, Repeats=trees, Padded=True, Activation=self.activation, \n",
    "                                         learn=False, alpha=1, beta=1, gamma=1, scale=scale, atten=atten,\n",
    "                                         leak=self.leak, Node_vary=False, positive=self.positive).cuda()\n",
    "                else:\n",
    "                    model = ktree_sparse(ds=ds, Repeats=trees, Padded=True, Activation=self.activation, \n",
    "                                         learn=False, alpha=1, beta=1, gamma=1, scale=scale, atten=atten,\n",
    "                                         synapse=False, leak=self.leak, Node_vary=False, positive=self.positive).cuda()\n",
    "            #Train and test ktree, assigning loss and acc values\n",
    "            if self.Synapse == True and self.model_type == 'ktree':\n",
    "                loss_curve, acc_curve, loss, acc, model_t = train_test_ktree_synapse(model, trainloaders[0],\n",
    "                                                                                validloaders[0], validloaders[0], \n",
    "                                                                                epochs = epochs, randorder=False,\n",
    "                                                                                lr=lr)\n",
    "            else:\n",
    "                loss_curve, acc_curve, loss, acc, model_t = train_test_ktree_sparse(model, trainloaders[0],\n",
    "                                                                                validloaders[0], validloaders[0], \n",
    "                                                                                epochs = epochs, randorder=False,\n",
    "                                                                                lr=lr)\n",
    "            break\n",
    "        if loss > 9:\n",
    "            status = 'fail'\n",
    "        else:\n",
    "            status = 'ok'\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'acc' : acc,\n",
    "            'status': status,\n",
    "            }\n",
    "    \n",
    "    def run_trials(self):\n",
    "\n",
    "        trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "        max_trials = 1  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "        file_label = '_'.join((self.model_type,self.activation,self.syn_key,self.pos_key,str(self.leak*100),self.dataset))\n",
    "        \n",
    "        try:  # try to load an already saved trials object, and increase the max\n",
    "            trials = pickle.load(open(self.DIR + file_label +'.hyperopt', \"rb\"))\n",
    "            print(\"Found saved Trials! Loading...\")\n",
    "            max_trials = len(trials.trials) + trials_step\n",
    "            print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "        except:  # create a new trials object and start searching\n",
    "            trials = Trials()\n",
    "\n",
    "        best = fmin(fn=self.objective, space=self.space, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "\n",
    "        print(\"Best:\", best)\n",
    "\n",
    "        # save the trials object\n",
    "        with open(self.DIR + file_label +'.hyperopt', \"wb\") as f:\n",
    "            pickle.dump(trials, f)\n",
    "            \n",
    "        if max_trials >= self.threshold:\n",
    "            return(False)\n",
    "        else:\n",
    "            return(True)\n",
    "    \n",
    "    def loop_to_threshold(self):\n",
    "        run_status = True\n",
    "        while run_status:\n",
    "            run_status = self.run_trials()\n",
    "        print('Threshold of '+str(self.threshold)+' reached')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ktree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nosyn posneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=0, \n",
    "                                    dataset='mnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=1, \n",
    "                                    dataset='fmnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=2, \n",
    "                                    dataset='kmnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=3, \n",
    "                                    dataset='emnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=4, \n",
    "                                    dataset='svhn', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=5, \n",
    "                                    dataset='usps', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=6, \n",
    "                                    dataset='cifar10', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nosyn pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=0, \n",
    "                                    dataset='mnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=1, \n",
    "                                    dataset='fmnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=2, \n",
    "                                    dataset='kmnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=3, \n",
    "                                    dataset='emnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=4, \n",
    "                                    dataset='svhn', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=5, \n",
    "                                    dataset='usps', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=6, \n",
    "                                    dataset='cifar10', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=False,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### syn posneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=0, \n",
    "                                    dataset='mnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=1, \n",
    "                                    dataset='fmnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=2, \n",
    "                                    dataset='kmnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=3, \n",
    "                                    dataset='emnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=4, \n",
    "                                    dataset='svhn', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=5, \n",
    "                                    dataset='usps', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=6, \n",
    "                                    dataset='cifar10', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=False)\n",
    "hyperoptimizer_syn.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### syn pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=0, \n",
    "                                    dataset='mnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=1, \n",
    "                                    dataset='fmnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=2, \n",
    "                                    dataset='kmnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=3, \n",
    "                                    dataset='emnist', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=4, \n",
    "                                    dataset='svhn', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=5, \n",
    "                                    dataset='usps', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_syn = Hyperoptimizer(model_type='ktree',\n",
    "                                    selector=6, \n",
    "                                    dataset='cifar10', \n",
    "                                    DIR='./results/20210205/', \n",
    "                                    threshold=300,\n",
    "                                    Synapse=True,\n",
    "                                    activation='sqgl',\n",
    "                                    leak=0.0,\n",
    "                                    positive=True)\n",
    "hyperoptimizer_syn.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu\n",
      "mnist {'nosyn': {'lr': 0.0058}}\n",
      "fmnist {'nosyn': {'lr': 0.006}}\n",
      "kmnist {'nosyn': {'lr': 0.001}}\n",
      "emnist {'nosyn': {'lr': 0.0043}}\n",
      "svhn {'nosyn': {'lr': 0.0079}}\n",
      "usps {'nosyn': {'lr': 0.0021}}\n",
      "cifar10 {'nosyn': {'lr': 0.0024}}\n",
      "lrelu\n",
      "mnist {'nosyn': {'lr': 0.0059}}\n",
      "fmnist {'nosyn': {'lr': 0.0006}}\n",
      "kmnist {'nosyn': {'lr': 0.0051}}\n",
      "emnist {'nosyn': {'lr': 0.0018}}\n",
      "svhn {'nosyn': {'lr': 0.0081}}\n",
      "usps {'nosyn': {'lr': 0.0056}}\n",
      "cifar10 {'nosyn': {'lr': 0.004}}\n",
      "sigmoid\n",
      "mnist {'nosyn': {'lr': 0.0068}}\n",
      "fmnist {'nosyn': {'lr': 0.0015}}\n",
      "kmnist {'nosyn': {'lr': 0.0049}}\n",
      "emnist {'nosyn': {'lr': 0.0077}}\n",
      "svhn {'nosyn': {'lr': 0.0012}}\n",
      "usps {'nosyn': {'lr': 0.0057}}\n",
      "cifar10 {'nosyn': {'lr': 0.0083}}\n",
      "swish\n",
      "mnist {'nosyn': {'lr': 0.0079}}\n",
      "fmnist {'nosyn': {'lr': 0.0001}}\n",
      "kmnist {'nosyn': {'lr': 0.0099}}\n",
      "emnist {'nosyn': {'lr': 0.0018}}\n",
      "svhn {'nosyn': {'lr': 0.0003}}\n",
      "usps {'nosyn': {'lr': 0.01}}\n",
      "cifar10 {'nosyn': {'lr': 0.0002}}\n",
      "sqgl\n",
      "mnist {'syn': {'pos': {'lr': 0.0012}, 'posneg': {'lr': 0.0001}}, 'nosyn': {'pos': {'lr': 0.0083}, 'posneg': {'lr': 0.0009}}}\n",
      "fmnist {'syn': {'pos': {'lr': 0.0017}, 'posneg': {'lr': 0.0083}}, 'nosyn': {'pos': {'lr': 0.0095}, 'posneg': {'lr': 0.0009}}}\n",
      "kmnist {'syn': {'pos': {'lr': 0.0001}, 'posneg': {'lr': 0.0001}}, 'nosyn': {'pos': {'lr': 0.0043}, 'posneg': {'lr': 0.0008}}}\n",
      "emnist {'syn': {'pos': {'lr': 0.0055}, 'posneg': {'lr': 0.002}}, 'nosyn': {'pos': {'lr': 0.0094}, 'posneg': {'lr': 0.0035}}}\n",
      "svhn {'syn': {'pos': {'lr': 0.0062}, 'posneg': {'lr': 0.0064}}, 'nosyn': {'pos': {'lr': 0.0066}, 'posneg': {'lr': 0.004}}}\n",
      "usps {'syn': {'pos': {'lr': 0.0056}, 'posneg': {'lr': 0.0029}}, 'nosyn': {'pos': {'lr': 0.0075}, 'posneg': {'lr': 0.0022}}}\n",
      "cifar10 {'syn': {'pos': {'lr': 0.0002}, 'posneg': {'lr': 0.0001}}, 'nosyn': {'pos': {'lr': 0.0085}, 'posneg': {'lr': 0.0017}}}\n"
     ]
    }
   ],
   "source": [
    "# Get list of classes\n",
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "class_names = classes[:,2]\n",
    "\n",
    "\n",
    "activations = ['relu', 'lrelu','sigmoid','swish','sqgl']\n",
    "\n",
    "syn_keys = ['syn', 'nosyn']\n",
    "pos_keys = ['pos', 'posneg']\n",
    "\n",
    "# Initialize dictionary\n",
    "sqgl_dict = {}\n",
    "\n",
    "# If synapse included, load from correct folder by assigning DIR path\n",
    "DIR = './results/20201227/'\n",
    "DIR_sqgl = './results/20210205/'\n",
    "    \n",
    "    \n",
    "# Load best hyperparameters for each dataset\n",
    "act_dict = {}\n",
    "for act in activations:\n",
    "\n",
    "    dataset_dict = {}\n",
    "    for dataset in class_names:\n",
    "\n",
    "        syn_dict = {}\n",
    "        if act == 'sqgl':\n",
    "            for syn_key in syn_keys:\n",
    "                pos_dict = {}\n",
    "                for pos_key in pos_keys:\n",
    "                    trials = pickle.load(open(DIR_sqgl + 'ktree_'+act+'_'+syn_key+'_'+pos_key+'_0.0_'+dataset+'.hyperopt', \"rb\"))\n",
    "                    lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                    pos_dict[pos_key] = {'lr' : lr}\n",
    "                syn_dict[syn_key] = pos_dict\n",
    "        else:\n",
    "            syn_key = 'nosyn'\n",
    "            \n",
    "            if act == 'lrelu':\n",
    "                trials = pickle.load(open(DIR + 'l_ktree_relu_'+dataset+'_'+syn_key+'.hyperopt', \"rb\"))\n",
    "                lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                syn_dict[syn_key] = {'lr' : lr}\n",
    "            else:\n",
    "                trials = pickle.load(open(DIR + 'ktree_'+act+'_'+dataset+'_'+syn_key+'.hyperopt', \"rb\"))\n",
    "                lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                syn_dict[syn_key] = {'lr' : lr}\n",
    "\n",
    "        dataset_dict[dataset] = syn_dict\n",
    "\n",
    "    act_dict[act] = dataset_dict\n",
    "\n",
    "for act in activations:\n",
    "    print(act)\n",
    "    for dataset in class_names:\n",
    "        \n",
    "        print(dataset, act_dict[act][dataset])\n",
    "        \n",
    "        \n",
    "with open('./results/hyperparameters/20210207_ktree_lr.hyperopt', 'wb') as handle:\n",
    "    pickle.dump(act_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nosyn posneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy')\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    # Initialize hyperoptimizer\n",
    "    hyperoptimizer_syn = Hyperoptimizer(model_type='fcnn',\n",
    "                                        selector=selector, \n",
    "                                        dataset=dataset, \n",
    "                                        DIR='./results/20210207/', \n",
    "                                        threshold=300,\n",
    "                                        Synapse=False,\n",
    "                                        activation='sqgl',\n",
    "                                        leak=0.0,\n",
    "                                        positive=False)\n",
    "    hyperoptimizer_syn.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### syn posneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy')\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    # Initialize hyperoptimizer\n",
    "    hyperoptimizer_syn = Hyperoptimizer(model_type='fcnn',\n",
    "                                        selector=selector, \n",
    "                                        dataset=dataset, \n",
    "                                        DIR='./results/20210207/', \n",
    "                                        threshold=300,\n",
    "                                        Synapse=True,\n",
    "                                        activation='sqgl',\n",
    "                                        leak=0.0,\n",
    "                                        positive=False)\n",
    "    hyperoptimizer_syn.loop_to_threshold()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu\n",
      "mnist {'nosyn': {'lr': 0.0011}}\n",
      "fmnist {'nosyn': {'lr': 0.0011}}\n",
      "kmnist {'nosyn': {'lr': 0.001}}\n",
      "emnist {'nosyn': {'lr': 0.0051}}\n",
      "svhn {'nosyn': {'lr': 0.001}}\n",
      "usps {'nosyn': {'lr': 0.0055}}\n",
      "cifar10 {'nosyn': {'lr': 0.0059}}\n",
      "lrelu\n",
      "mnist {'nosyn': {'lr': 0.0045}}\n",
      "fmnist {'nosyn': {'lr': 0.008}}\n",
      "kmnist {'nosyn': {'lr': 0.0052}}\n",
      "emnist {'nosyn': {'lr': 0.0095}}\n",
      "svhn {'nosyn': {'lr': 0.0073}}\n",
      "usps {'nosyn': {'lr': 0.0033}}\n",
      "cifar10 {'nosyn': {'lr': 0.0082}}\n",
      "sigmoid\n",
      "mnist {'nosyn': {'lr': 0.0008}}\n",
      "fmnist {'nosyn': {'lr': 0.0039}}\n",
      "kmnist {'nosyn': {'lr': 0.0069}}\n",
      "emnist {'nosyn': {'lr': 0.0047}}\n",
      "svhn {'nosyn': {'lr': 0.0067}}\n",
      "usps {'nosyn': {'lr': 0.0082}}\n",
      "cifar10 {'nosyn': {'lr': 0.0059}}\n",
      "swish\n",
      "mnist {'nosyn': {'lr': 0.0081}}\n",
      "fmnist {'nosyn': {'lr': 0.0028}}\n",
      "kmnist {'nosyn': {'lr': 0.0032}}\n",
      "emnist {'nosyn': {'lr': 0.0004}}\n",
      "svhn {'nosyn': {'lr': 0.0001}}\n",
      "usps {'nosyn': {'lr': 0.0036}}\n",
      "cifar10 {'nosyn': {'lr': 0.003}}\n",
      "sqgl\n",
      "mnist {'syn': {'posneg': {'lr': 0.0021}}, 'nosyn': {'posneg': {'lr': 0.0059}}}\n",
      "fmnist {'syn': {'posneg': {'lr': 0.0012}}, 'nosyn': {'posneg': {'lr': 0.0034}}}\n",
      "kmnist {'syn': {'posneg': {'lr': 0.0017}}, 'nosyn': {'posneg': {'lr': 0.0051}}}\n",
      "emnist {'syn': {'posneg': {'lr': 0.0028}}, 'nosyn': {'posneg': {'lr': 0.0087}}}\n",
      "svhn {'syn': {'posneg': {'lr': 0.0088}}, 'nosyn': {'posneg': {'lr': 0.0032}}}\n",
      "usps {'syn': {'posneg': {'lr': 0.008}}, 'nosyn': {'posneg': {'lr': 0.0071}}}\n",
      "cifar10 {'syn': {'posneg': {'lr': 0.0001}}, 'nosyn': {'posneg': {'lr': 0.0001}}}\n"
     ]
    }
   ],
   "source": [
    "# Get list of classes\n",
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "class_names = classes[:,2]\n",
    "\n",
    "\n",
    "activations = ['relu', 'lrelu','sigmoid','swish','sqgl']\n",
    "\n",
    "syn_keys = ['syn', 'nosyn']\n",
    "pos_keys = ['posneg']\n",
    "\n",
    "# Initialize dictionary\n",
    "sqgl_dict = {}\n",
    "\n",
    "# If synapse included, load from correct folder by assigning DIR path\n",
    "DIR = './results/20201229/'\n",
    "DIR_sqgl = './results/20210207/'\n",
    "    \n",
    "    \n",
    "# Load best hyperparameters for each dataset\n",
    "act_dict = {}\n",
    "for act in activations:\n",
    "\n",
    "    dataset_dict = {}\n",
    "    for dataset in class_names:\n",
    "        syn_dict = {}\n",
    "        if act == 'sqgl':\n",
    "            for syn_key in syn_keys:\n",
    "                pos_dict = {}\n",
    "                for pos_key in pos_keys:\n",
    "                    trials = pickle.load(open(DIR_sqgl + 'fcnn_'+act+'_'+syn_key+'_'+pos_key+'_0.0_'+dataset+'.hyperopt', \"rb\"))\n",
    "                    lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                    pos_dict[pos_key] = {'lr' : lr}\n",
    "                syn_dict[syn_key] = pos_dict\n",
    "        else:\n",
    "            syn_key = 'nosyn'\n",
    "            \n",
    "            if act == 'lrelu':\n",
    "                trials = pickle.load(open(DIR + 'l_fcnn_relu_'+dataset+'_'+syn_key+'.hyperopt', \"rb\"))\n",
    "                lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                syn_dict[syn_key] = {'lr' : lr}\n",
    "            else:\n",
    "                trials = pickle.load(open(DIR + 'fcnn_'+act+'_'+dataset+'_'+syn_key+'.hyperopt', \"rb\"))\n",
    "                lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                syn_dict[syn_key] = {'lr' : lr}\n",
    "\n",
    "        dataset_dict[dataset] = syn_dict\n",
    "\n",
    "    act_dict[act] = dataset_dict\n",
    "\n",
    "for act in activations:\n",
    "    print(act)\n",
    "    for dataset in class_names:\n",
    "        \n",
    "        print(dataset, act_dict[act][dataset])\n",
    "        \n",
    "        \n",
    "with open('./results/hyperparameters/20210207_fcnn_lr.hyperopt', 'wb') as handle:\n",
    "    pickle.dump(act_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py36_1] *",
   "language": "python",
   "name": "conda-env-.conda-py36_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

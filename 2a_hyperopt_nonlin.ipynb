{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt Nonlinearities\n",
    "\n",
    "#### Important Note: SQGL Learning Rates will be found using 3_hyperopt_LR_SQGL.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fit_params.fit_functions import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from custompackage.load_architecture import *\n",
    "from custompackage.load_data import *\n",
    "from custompackage.traintestloop import *\n",
    "\n",
    "import sparselinear as sl\n",
    "import custompackage.sl_custom as slc\n",
    "\n",
    "import hyperopt as hp\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperoptimization Class\n",
    "- Activation functions: ReLU, LReLU, Sigmoid, SiLU, Swish, SQGL\n",
    "- Learning-rate focused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperoptimizer():\n",
    "    '''\n",
    "    - Includes objective function methods\n",
    "    - Includes run trials\n",
    "    - Includes \"while true\" loop\n",
    "    - Parameters will be: dataset, file location, types of hyperparameters optimized\n",
    "    - Activation functions: ReLU, LReLU, Sigmoid, SiLU, Swish, SQGL\n",
    "    - Learning-rate focused\n",
    "    '''\n",
    "    def __init__(self, selector=0, dataset='mnist', activation='sqgl', DIR='./results/temp/', \n",
    "                 threshold=300, Synapse=False, leak=0.01):\n",
    "        self.selector = selector\n",
    "        self.dataset = dataset\n",
    "        self.activation = activation\n",
    "        self.DIR = DIR\n",
    "        self.threshold = threshold\n",
    "        self.Synapse = Synapse\n",
    "        self.leak = leak\n",
    "        \n",
    "        if self.Synapse == True:\n",
    "            self.syn_key = 'syn'\n",
    "        else:\n",
    "            self.syn_key = 'nosyn'\n",
    "        \n",
    "        self.space = hp.choice('a',\n",
    "                                [\n",
    "                                    {\n",
    "                                        'lr': hp.uniform('lr', 0.0001, 0.01)\n",
    "                                    }\n",
    "                                ])\n",
    "    \n",
    "    def objective(self, params):\n",
    "        \n",
    "        #Hyperparameter to be optimized\n",
    "        lr = params['lr']\n",
    "        \n",
    "        #SQGL parameters if appropriate\n",
    "        atten = 0.5\n",
    "        scale = 1\n",
    "        \n",
    "        # Initialize settings\n",
    "        bs = 256\n",
    "        weighting = 'paired'\n",
    "        trials = 10\n",
    "        epochs = 2000\n",
    "        trees_set = [1]\n",
    "        trees = trees_set[0]\n",
    "\n",
    "        # Load class-dataset list\n",
    "        classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "        classes = [classes[self.selector]]\n",
    "\n",
    "\n",
    "        # For each dataset enumerated from classes list\n",
    "        for j, (t1, t2, ds) in enumerate(classes):\n",
    "            print(t1, t2, ds)\n",
    "            # Load data loaders\n",
    "            trainloaders, validloaders, testloader = dataset_weighted_split_all(bs, t1, t2, weighting, trials, ds, permute=False)\n",
    "            # Initialize input size for model initialization purposes\n",
    "            input_size = trainloaders[0].dataset.tensors[0][0].shape[0]\n",
    "            # For each trial\n",
    "            # Initialize the ktree model\n",
    "            model = ktree_sparse(ds=ds, Repeats=trees, Padded=True, Activation=self.activation, learn=False, \n",
    "                                 alpha=1, beta=1, gamma=1, scale=scale, atten=atten,\n",
    "                                 synapse=self.Synapse, leak=self.leak).cuda()\n",
    "            #Train and test ktree, assigning loss and acc values\n",
    "            loss_curve, acc_curve, loss, acc, model_t = train_test_ktree_sparse(model, trainloaders[0],\n",
    "                                                                                validloaders[0], validloaders[0], \n",
    "                                                                                epochs = epochs, randorder=False,\n",
    "                                                                                lr=lr)\n",
    "            break\n",
    "        if loss > 9:\n",
    "            status = 'fail'\n",
    "        else:\n",
    "            status = 'ok'\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'acc' : acc,\n",
    "            'status': status,\n",
    "            }\n",
    "    \n",
    "    def run_trials(self):\n",
    "\n",
    "        trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "        max_trials = 1  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "\n",
    "        try:  # try to load an already saved trials object, and increase the max\n",
    "            trials = pickle.load(open(self.DIR + 'ktree_'+self.activation+'_'+self.dataset+'_'+self.syn_key+'.hyperopt', \"rb\"))\n",
    "            print(\"Found saved Trials! Loading...\")\n",
    "            max_trials = len(trials.trials) + trials_step\n",
    "            print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "        except:  # create a new trials object and start searching\n",
    "            trials = Trials()\n",
    "\n",
    "        best = fmin(fn=self.objective, space=self.space, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "\n",
    "        print(\"Best:\", best)\n",
    "\n",
    "        # save the trials object\n",
    "        with open(self.DIR + 'ktree_'+self.activation+'_'+self.dataset+'_'+self.syn_key+'.hyperopt', \"wb\") as f:\n",
    "            pickle.dump(trials, f)\n",
    "            \n",
    "        if max_trials >= self.threshold:\n",
    "            return(False)\n",
    "        else:\n",
    "            return(True)\n",
    "    \n",
    "    def loop_to_threshold(self):\n",
    "        run_status = True\n",
    "        while run_status:\n",
    "            run_status = self.run_trials()\n",
    "        print('Threshold of '+str(self.threshold)+' reached')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt learning rate for each activation function for each dataset\n",
    "ReLU, LReLU, Sigmoid, SiLU, Swish, SQGL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_mnist = Hyperoptimizer(selector=0, \n",
    "                                      dataset='mnist',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_mnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_fmnist = Hyperoptimizer(selector=1, \n",
    "                                      dataset='fmnist',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_fmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_kmnist = Hyperoptimizer(selector=2, \n",
    "                                      dataset='kmnist',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_kmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_emnist = Hyperoptimizer(selector=3, \n",
    "                                      dataset='emnist',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_emnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_svhn = Hyperoptimizer(selector=4, \n",
    "                                      dataset='svhn',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_svhn.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_usps = Hyperoptimizer(selector=5, \n",
    "                                      dataset='usps',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_usps.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_cifar10 = Hyperoptimizer(selector=6, \n",
    "                                      dataset='cifar10',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_cifar10.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LReLU nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_mnist = Hyperoptimizer(selector=0, \n",
    "                                      dataset='mnist',\n",
    "                                      activation='relu',,\n",
    "                                      DIR='./results/20201227/l_', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0.01)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_mnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_fmnist = Hyperoptimizer(selector=1, \n",
    "                                      dataset='fmnist',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/l_', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0.01)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_fmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_kmnist = Hyperoptimizer(selector=2, \n",
    "                                      dataset='kmnist',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/l_', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0.01)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_kmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_emnist = Hyperoptimizer(selector=3, \n",
    "                                      dataset='emnist',\n",
    "                                      activation='relu',,\n",
    "                                      DIR='./results/20201227/l_', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0.01)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_emnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_svhn = Hyperoptimizer(selector=4, \n",
    "                                      dataset='svhn',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/l_', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0.01)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_svhn.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_usps = Hyperoptimizer(selector=5, \n",
    "                                      dataset='usps',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/l_', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0.01)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_usps.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_cifar10 = Hyperoptimizer(selector=6, \n",
    "                                      dataset='cifar10',\n",
    "                                      activation='relu',\n",
    "                                      DIR='./results/20201227/l_', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False,\n",
    "                                      leak=0.01)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_cifar10.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_mnist = Hyperoptimizer(selector=0, \n",
    "                                      dataset='mnist',\n",
    "                                      activation='sigmoid',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_mnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_fmnist = Hyperoptimizer(selector=1, \n",
    "                                      dataset='fmnist',\n",
    "                                      activation='sigmoid',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_fmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_kmnist = Hyperoptimizer(selector=2, \n",
    "                                      dataset='kmnist',\n",
    "                                      activation='sigmoid',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_kmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_emnist = Hyperoptimizer(selector=3, \n",
    "                                      dataset='emnist',\n",
    "                                      activation='sigmoid',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_emnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_svhn = Hyperoptimizer(selector=4, \n",
    "                                      dataset='svhn',\n",
    "                                      activation='sigmoid',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_svhn.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_usps = Hyperoptimizer(selector=5, \n",
    "                                      dataset='usps',\n",
    "                                      activation='sigmoid',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_usps.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_cifar10 = Hyperoptimizer(selector=6, \n",
    "                                      dataset='cifar10',\n",
    "                                      activation='sigmoid',\n",
    "                     ,                 DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_cifar10.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SiLU nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_mnist = Hyperoptimizer(selector=0, \n",
    "                                      dataset='mnist',\n",
    "                                      activation='silu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_mnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_fmnist = Hyperoptimizer(selector=1, \n",
    "                                      dataset='fmnist',\n",
    "                                      activation='silu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_fmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_kmnist = Hyperoptimizer(selector=2, \n",
    "                                      dataset='kmnist',\n",
    "                                      activation='silu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_kmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_emnist = Hyperoptimizer(selector=3, \n",
    "                                      dataset='emnist',\n",
    "                                      activation='silu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_emnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_svhn = Hyperoptimizer(selector=4, \n",
    "                                      dataset='svhn',\n",
    "                                      activation='silu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_svhn.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_usps = Hyperoptimizer(selector=5, \n",
    "                                      dataset='usps',\n",
    "                                      activation='silu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_usps.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_cifar10 = Hyperoptimizer(selector=6, \n",
    "                                      dataset='cifar10',\n",
    "                                      activation='silu',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_cifar10.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swish nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_mnist = Hyperoptimizer(selector=0, \n",
    "                                      dataset='mnist',\n",
    "                                      activation='swish',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_mnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_fmnist = Hyperoptimizer(selector=1, \n",
    "                                      dataset='fmnist',\n",
    "                                      activation='swish',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_fmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_kmnist = Hyperoptimizer(selector=2, \n",
    "                                      dataset='kmnist',\n",
    "                                      activation='swish',,\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_kmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_emnist = Hyperoptimizer(selector=3, \n",
    "                                      dataset='emnist',\n",
    "                                      activation='swish',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_emnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_svhn = Hyperoptimizer(selector=4, \n",
    "                                      dataset='svhn',\n",
    "                                      activation='swish',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_svhn.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_usps = Hyperoptimizer(selector=5, \n",
    "                                      dataset='usps',\n",
    "                                      activation='swish',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_usps.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_cifar10 = Hyperoptimizer(selector=6, \n",
    "                                      dataset='cifar10',\n",
    "                                      activation='swish',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_cifar10.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQGL nonlinearity without Synapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_mnist = Hyperoptimizer(selector=0, \n",
    "                                      dataset='mnist',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_mnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_fmnist = Hyperoptimizer(selector=1, \n",
    "                                      dataset='fmnist',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_fmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_kmnist = Hyperoptimizer(selector=2, \n",
    "                                      dataset='kmnist',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_kmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_emnist = Hyperoptimizer(selector=3, \n",
    "                                      dataset='emnist',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_emnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_svhn = Hyperoptimizer(selector=4, \n",
    "                                      dataset='svhn',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_svhn.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_usps = Hyperoptimizer(selector=5, \n",
    "                                      dataset='usps',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_usps.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_cifar10 = Hyperoptimizer(selector=6, \n",
    "                                      dataset='cifar10',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=False)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_cifar10.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQGL nonlinearity with Synapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_mnist = Hyperoptimizer(selector=0, \n",
    "                                      dataset='mnist',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=True)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_mnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_fmnist = Hyperoptimizer(selector=1, \n",
    "                                      dataset='fmnist',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=True)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_fmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_kmnist = Hyperoptimizer(selector=2, \n",
    "                                      dataset='kmnist',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=True)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_kmnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_emnist = Hyperoptimizer(selector=3, \n",
    "                                      dataset='emnist',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=True)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_emnist.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_svhn = Hyperoptimizer(selector=4, \n",
    "                                      dataset='svhn',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=True)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_svhn.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_usps = Hyperoptimizer(selector=5, \n",
    "                                      dataset='usps',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=True)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_usps.loop_to_threshold()\n",
    "\n",
    "\n",
    "# Initialize hyperoptimizer\n",
    "hyperoptimizer_cifar10 = Hyperoptimizer(selector=6, \n",
    "                                      dataset='cifar10',\n",
    "                                      activation='sqgl',\n",
    "                                      DIR='./results/20201227/', \n",
    "                                      threshold=300,\n",
    "                                      Synapse=True)\n",
    "\n",
    "# Run hyperoptimizer until threshold for number of trials is reached\n",
    "hyperoptimizer_cifar10.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect best learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu\n",
      "mnist {'nosyn': {'lr': 0.0058}}\n",
      "fmnist {'nosyn': {'lr': 0.006}}\n",
      "kmnist {'nosyn': {'lr': 0.001}}\n",
      "emnist {'nosyn': {'lr': 0.0043}}\n",
      "svhn {'nosyn': {'lr': 0.0079}}\n",
      "usps {'nosyn': {'lr': 0.0021}}\n",
      "cifar10 {'nosyn': {'lr': 0.0024}}\n",
      "lrelu\n",
      "mnist {'nosyn': {'lr': 0.0059}}\n",
      "fmnist {'nosyn': {'lr': 0.0006}}\n",
      "kmnist {'nosyn': {'lr': 0.0051}}\n",
      "emnist {'nosyn': {'lr': 0.0018}}\n",
      "svhn {'nosyn': {'lr': 0.0081}}\n",
      "usps {'nosyn': {'lr': 0.0056}}\n",
      "cifar10 {'nosyn': {'lr': 0.004}}\n",
      "sigmoid\n",
      "mnist {'nosyn': {'lr': 0.0068}}\n",
      "fmnist {'nosyn': {'lr': 0.0015}}\n",
      "kmnist {'nosyn': {'lr': 0.0049}}\n",
      "emnist {'nosyn': {'lr': 0.0077}}\n",
      "svhn {'nosyn': {'lr': 0.0012}}\n",
      "usps {'nosyn': {'lr': 0.0057}}\n",
      "cifar10 {'nosyn': {'lr': 0.0083}}\n",
      "swish\n",
      "mnist {'nosyn': {'lr': 0.0079}}\n",
      "fmnist {'nosyn': {'lr': 0.0001}}\n",
      "kmnist {'nosyn': {'lr': 0.0099}}\n",
      "emnist {'nosyn': {'lr': 0.0018}}\n",
      "svhn {'nosyn': {'lr': 0.0003}}\n",
      "usps {'nosyn': {'lr': 0.01}}\n",
      "cifar10 {'nosyn': {'lr': 0.0002}}\n",
      "sqgl\n",
      "mnist {'syn': {'lr': 0.0007}, 'nosyn': {'lr': 0.003}}\n",
      "fmnist {'syn': {'lr': 0.0016}, 'nosyn': {'lr': 0.0054}}\n",
      "kmnist {'syn': {'lr': 0.0059}, 'nosyn': {'lr': 0.0024}}\n",
      "emnist {'syn': {'lr': 0.008}, 'nosyn': {'lr': 0.0039}}\n",
      "svhn {'syn': {'lr': 0.0006}, 'nosyn': {'lr': 0.0001}}\n",
      "usps {'syn': {'lr': 0.0063}, 'nosyn': {'lr': 0.003}}\n",
      "cifar10 {'syn': {'lr': 0.0058}, 'nosyn': {'lr': 0.0006}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get list of classes\n",
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "class_names = classes[:,2]\n",
    "\n",
    "\n",
    "activations = ['relu', 'lrelu','sigmoid','swish','sqgl']\n",
    "\n",
    "syn_keys = ['syn', 'nosyn']\n",
    "\n",
    "# Initialize dictionary\n",
    "sqgl_dict = {}\n",
    "\n",
    "# If synapse included, load from correct folder by assigning DIR path\n",
    "DIR = './results/20201227/'\n",
    "    \n",
    "    \n",
    "# Load best hyperparameters for each dataset\n",
    "act_dict = {}\n",
    "for act in activations:\n",
    "\n",
    "    dataset_dict = {}\n",
    "    for dataset in class_names:\n",
    "\n",
    "        syn_dict = {}\n",
    "        if act == 'sqgl':\n",
    "            for syn_key in syn_keys:\n",
    "                trials = pickle.load(open(DIR + 'ktree_'+act+'_'+dataset+'_'+syn_key+'.hyperopt', \"rb\"))\n",
    "                lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                syn_dict[syn_key] = {'lr' : lr}\n",
    "        else:\n",
    "            syn_key = 'nosyn'\n",
    "            \n",
    "            if act == 'lrelu':\n",
    "                trials = pickle.load(open(DIR + 'l_ktree_relu_'+dataset+'_'+syn_key+'.hyperopt', \"rb\"))\n",
    "                lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                syn_dict[syn_key] = {'lr' : lr}\n",
    "            else:\n",
    "                trials = pickle.load(open(DIR + 'ktree_'+act+'_'+dataset+'_'+syn_key+'.hyperopt', \"rb\"))\n",
    "                lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                syn_dict[syn_key] = {'lr' : lr}\n",
    "\n",
    "        dataset_dict[dataset] = syn_dict\n",
    "\n",
    "    act_dict[act] = dataset_dict\n",
    "\n",
    "for act in activations:\n",
    "    print(act)\n",
    "    for dataset in class_names:\n",
    "        \n",
    "        print(dataset, act_dict[act][dataset])\n",
    "        \n",
    "\n",
    "\n",
    "with open('./results/hyperparameters/ktree_lr.hyperopt', 'wb') as handle:\n",
    "    pickle.dump(act_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperoptimize learning rate for FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperoptimizer_fcnn():\n",
    "    '''\n",
    "    - Includes objective function methods\n",
    "    - Includes run trials\n",
    "    - Includes \"while true\" loop\n",
    "    - Parameters will be: dataset, file location, types of hyperparameters optimized\n",
    "    - Activation functions: ReLU, LReLU, Sigmoid, SiLU, Swish, SQGL\n",
    "    - Learning-rate focused\n",
    "    '''\n",
    "    def __init__(self, selector=0, dataset='mnist', activation='sqgl', DIR='./results/temp/', \n",
    "                 threshold=300, Synapse=False, leak=0.01):\n",
    "        self.selector = selector\n",
    "        self.dataset = dataset\n",
    "        self.activation = activation\n",
    "        self.DIR = DIR\n",
    "        self.threshold = threshold\n",
    "        self.Synapse = Synapse\n",
    "        self.leak = leak\n",
    "        \n",
    "        if self.Synapse == True:\n",
    "            self.syn_key = 'syn'\n",
    "        else:\n",
    "            self.syn_key = 'nosyn'\n",
    "        \n",
    "        self.space = hp.choice('a',\n",
    "                                [\n",
    "                                    {\n",
    "                                        'lr': hp.uniform('lr', 0.0001, 0.01)\n",
    "                                    }\n",
    "                                ])\n",
    "    \n",
    "    def objective(self, params):\n",
    "        \n",
    "        #Hyperparameter to be optimized\n",
    "        lr = params['lr']\n",
    "        \n",
    "        #SQGL parameters if appropriate\n",
    "        \n",
    "        atten = 0.5\n",
    "        scale = 1\n",
    "        \n",
    "        # Initialize settings\n",
    "        bs = 256\n",
    "        weighting = 'paired'\n",
    "        trials = 10\n",
    "        epochs = 2000\n",
    "        trees_set = [1]\n",
    "        trees = trees_set[0]\n",
    "\n",
    "        # Load class-dataset list\n",
    "        classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "        classes = [classes[self.selector]]\n",
    "\n",
    "\n",
    "        # For each dataset enumerated from classes list\n",
    "        for j, (t1, t2, ds) in enumerate(classes):\n",
    "            print(t1, t2, ds)\n",
    "            # Load data loaders\n",
    "            trainloaders, validloaders, testloader = dataset_weighted_split_all(bs, t1, t2, weighting, trials, ds, permute=False)\n",
    "            # Initialize input size for model initialization purposes\n",
    "            input_size = trainloaders[0].dataset.tensors[0][0].shape[0]\n",
    "            # For each trial\n",
    "            # Initialize the ktree model\n",
    "            if self.Synapse == True:\n",
    "                model = synapse_fcnn(Input_size=input_size, Hidden_size=trees*2, Output_size=1,\n",
    "                                     Activation='sqgl', learn=False, alpha=1, beta=1, gamma=1, \n",
    "                                     scale=scale, atten=atten, leak=self.leak).cuda()\n",
    "            else:\n",
    "                model = simple_fcnn(Input_size=input_size, Hidden_size=trees*2, Output_size=1,\n",
    "                                     Activation='sqgl', learn=False, alpha=1, beta=1, gamma=1, \n",
    "                                     scale=scale, atten=atten, leak=self.leak).cuda()\n",
    "            #Train and test ktree, assigning loss and acc values\n",
    "            loss_curve, acc_curve, loss, acc, model_t = train_test_ktree_sparse(model, trainloaders[0],\n",
    "                                                                                validloaders[0], validloaders[0], \n",
    "                                                                                epochs = epochs, randorder=False,\n",
    "                                                                                lr=lr)\n",
    "            break\n",
    "        if loss > 9:\n",
    "            status = 'fail'\n",
    "        else:\n",
    "            status = 'ok'\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'acc' : acc,\n",
    "            'status': status,\n",
    "            }\n",
    "    \n",
    "    def run_trials(self):\n",
    "\n",
    "        trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "        max_trials = 1  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "\n",
    "        try:  # try to load an already saved trials object, and increase the max\n",
    "            trials = pickle.load(open(self.DIR + 'fcnn_'+self.activation+'_'+self.dataset+'_'+self.syn_key+'.hyperopt', \"rb\"))\n",
    "            print(\"Found saved Trials! Loading...\")\n",
    "            max_trials = len(trials.trials) + trials_step\n",
    "            print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "        except:  # create a new trials object and start searching\n",
    "            trials = Trials()\n",
    "\n",
    "        best = fmin(fn=self.objective, space=self.space, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "\n",
    "        print(\"Best:\", best)\n",
    "\n",
    "        # save the trials object\n",
    "        with open(self.DIR + 'fcnn_'+self.activation+'_'+self.dataset+'_'+self.syn_key+'.hyperopt', \"wb\") as f:\n",
    "            pickle.dump(trials, f)\n",
    "            \n",
    "        if max_trials >= self.threshold:\n",
    "            return(False)\n",
    "        else:\n",
    "            return(True)\n",
    "    \n",
    "    def loop_to_threshold(self):\n",
    "        run_status = True\n",
    "        while run_status:\n",
    "            run_status = self.run_trials()\n",
    "        print('Threshold of '+str(self.threshold)+' reached')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for dataset in classes:\n",
    "    hyperoptimizer = Hyperoptimizer_fcnn(selector=0, \n",
    "                                          dataset=dataset,\n",
    "                                          activation='relu',\n",
    "                                          DIR='./results/20201229/', \n",
    "                                          threshold=300,\n",
    "                                          Synapse=False,\n",
    "                                          leak=0)\n",
    "\n",
    "    # Run hyperoptimizer until threshold for number of trials is reached\n",
    "    hyperoptimizer.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LReLU Nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for dataset in classes:\n",
    "    hyperoptimizer = Hyperoptimizer_fcnn(selector=0, \n",
    "                                          dataset=dataset,\n",
    "                                          activation='relu',\n",
    "                                          DIR='./results/20201229/l_', \n",
    "                                          threshold=300,\n",
    "                                          Synapse=False,\n",
    "                                          leak=0.01)\n",
    "\n",
    "    # Run hyperoptimizer until threshold for number of trials is reached\n",
    "    hyperoptimizer.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for dataset in classes:\n",
    "    hyperoptimizer = Hyperoptimizer_fcnn(selector=0, \n",
    "                                          dataset=dataset,\n",
    "                                          activation='sigmoid',\n",
    "                                          DIR='./results/20201229/', \n",
    "                                          threshold=300,\n",
    "                                          Synapse=False)\n",
    "\n",
    "    # Run hyperoptimizer until threshold for number of trials is reached\n",
    "    hyperoptimizer.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swish Nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for dataset in classes:\n",
    "    hyperoptimizer = Hyperoptimizer_fcnn(selector=0, \n",
    "                                          dataset=dataset,\n",
    "                                          activation='swish',\n",
    "                                          DIR='./results/20201229/', \n",
    "                                          threshold=300,\n",
    "                                          Synapse=False)\n",
    "\n",
    "    # Run hyperoptimizer until threshold for number of trials is reached\n",
    "    hyperoptimizer.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQGL w/o Synapse Nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for dataset in classes:\n",
    "    hyperoptimizer = Hyperoptimizer_fcnn(selector=0, \n",
    "                                          dataset=dataset,\n",
    "                                          activation='sqgl',\n",
    "                                          DIR='./results/20201229/', \n",
    "                                          threshold=300,\n",
    "                                          Synapse=False)\n",
    "\n",
    "    # Run hyperoptimizer until threshold for number of trials is reached\n",
    "    hyperoptimizer.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQGL w/ Synapse Nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperoptimizer\n",
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for dataset in classes:\n",
    "    hyperoptimizer = Hyperoptimizer_fcnn(selector=0, \n",
    "                                          dataset=dataset,\n",
    "                                          activation='sqgl',\n",
    "                                          DIR='./results/20201229/', \n",
    "                                          threshold=300,\n",
    "                                          Synapse=True)\n",
    "\n",
    "    # Run hyperoptimizer until threshold for number of trials is reached\n",
    "    hyperoptimizer.loop_to_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect learning rates for FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu\n",
      "mnist {'nosyn': {'lr': 0.0011}}\n",
      "fmnist {'nosyn': {'lr': 0.0011}}\n",
      "kmnist {'nosyn': {'lr': 0.001}}\n",
      "emnist {'nosyn': {'lr': 0.0051}}\n",
      "svhn {'nosyn': {'lr': 0.001}}\n",
      "usps {'nosyn': {'lr': 0.0055}}\n",
      "cifar10 {'nosyn': {'lr': 0.0059}}\n",
      "lrelu\n",
      "mnist {'nosyn': {'lr': 0.0045}}\n",
      "fmnist {'nosyn': {'lr': 0.008}}\n",
      "kmnist {'nosyn': {'lr': 0.0052}}\n",
      "emnist {'nosyn': {'lr': 0.0095}}\n",
      "svhn {'nosyn': {'lr': 0.0073}}\n",
      "usps {'nosyn': {'lr': 0.0033}}\n",
      "cifar10 {'nosyn': {'lr': 0.0082}}\n",
      "sigmoid\n",
      "mnist {'nosyn': {'lr': 0.0008}}\n",
      "fmnist {'nosyn': {'lr': 0.0039}}\n",
      "kmnist {'nosyn': {'lr': 0.0069}}\n",
      "emnist {'nosyn': {'lr': 0.0047}}\n",
      "svhn {'nosyn': {'lr': 0.0067}}\n",
      "usps {'nosyn': {'lr': 0.0082}}\n",
      "cifar10 {'nosyn': {'lr': 0.0059}}\n",
      "swish\n",
      "mnist {'nosyn': {'lr': 0.0081}}\n",
      "fmnist {'nosyn': {'lr': 0.0028}}\n",
      "kmnist {'nosyn': {'lr': 0.0032}}\n",
      "emnist {'nosyn': {'lr': 0.0004}}\n",
      "svhn {'nosyn': {'lr': 0.0001}}\n",
      "usps {'nosyn': {'lr': 0.0036}}\n",
      "cifar10 {'nosyn': {'lr': 0.003}}\n",
      "sqgl\n",
      "mnist {'syn': {'lr': 0.0063}, 'nosyn': {'lr': 0.0016}}\n",
      "fmnist {'syn': {'lr': 0.006}, 'nosyn': {'lr': 0.0006}}\n",
      "kmnist {'syn': {'lr': 0.0006}, 'nosyn': {'lr': 0.0007}}\n",
      "emnist {'syn': {'lr': 0.0054}, 'nosyn': {'lr': 0.0038}}\n",
      "svhn {'syn': {'lr': 0.0003}, 'nosyn': {'lr': 0.0023}}\n",
      "usps {'syn': {'lr': 0.0001}, 'nosyn': {'lr': 0.0002}}\n",
      "cifar10 {'syn': {'lr': 0.0001}, 'nosyn': {'lr': 0.0065}}\n"
     ]
    }
   ],
   "source": [
    "# Get list of classes\n",
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "class_names = classes[:,2]\n",
    "\n",
    "\n",
    "activations = ['relu', 'lrelu','sigmoid','swish','sqgl']\n",
    "\n",
    "syn_keys = ['syn', 'nosyn']\n",
    "\n",
    "# Initialize dictionary\n",
    "sqgl_dict = {}\n",
    "\n",
    "# If synapse included, load from correct folder by assigning DIR path\n",
    "DIR = './results/20201229/'\n",
    "    \n",
    "    \n",
    "# Load best hyperparameters for each dataset\n",
    "act_dict = {}\n",
    "for act in activations:\n",
    "\n",
    "    dataset_dict = {}\n",
    "    for dataset in class_names:\n",
    "\n",
    "        syn_dict = {}\n",
    "        if act == 'sqgl':\n",
    "            for syn_key in syn_keys:\n",
    "                trials = pickle.load(open(DIR + 'fcnn_'+act+'_'+dataset+'_'+syn_key+'.hyperopt', \"rb\"))\n",
    "                lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                syn_dict[syn_key] = {'lr' : lr}\n",
    "        else:\n",
    "            syn_key = 'nosyn'\n",
    "            \n",
    "            if act == 'lrelu':\n",
    "                trials = pickle.load(open(DIR + 'l_fcnn_relu_'+dataset+'_'+syn_key+'.hyperopt', \"rb\"))\n",
    "                lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                syn_dict[syn_key] = {'lr' : lr}\n",
    "            else:\n",
    "                trials = pickle.load(open(DIR + 'fcnn_'+act+'_'+dataset+'_'+syn_key+'.hyperopt', \"rb\"))\n",
    "                lr = round(trials.best_trial['misc']['vals']['lr'][0], 4)\n",
    "                syn_dict[syn_key] = {'lr' : lr}\n",
    "\n",
    "        dataset_dict[dataset] = syn_dict\n",
    "\n",
    "    act_dict[act] = dataset_dict\n",
    "\n",
    "for act in activations:\n",
    "    print(act)\n",
    "    for dataset in class_names:\n",
    "        \n",
    "        print(dataset, act_dict[act][dataset])\n",
    "        \n",
    "# with open('./results/hyperparameters/fcnn_lr.hyperopt', 'wb') as handle:\n",
    "#     pickle.dump(act_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py36_1] *",
   "language": "python",
   "name": "conda-env-.conda-py36_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

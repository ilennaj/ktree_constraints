{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing nonlinearities\n",
    "\n",
    "Running ReLU, LReLU, Sigmoid, Swish, and SQGL (with and without synapses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from fit_params.fit_functions import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from custompackage.load_architecture import *\n",
    "from custompackage.load_data import *\n",
    "from custompackage.traintestloop import *\n",
    "\n",
    "import sparselinear as sl\n",
    "import custompackage.sl_custom as slc\n",
    "\n",
    "import hyperopt as hp\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize class for running each nonlinearity for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nonlinearities():\n",
    "    '''\n",
    "    Establish nonlinearity, synapse status, directory, leak\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, model_type='ktree', activation='relu', selector=0, dataset='mnist', \n",
    "                 DIR='./results/temp/', Synapse=False, leak=0.01):\n",
    "        \n",
    "        self.model_type = model_type\n",
    "        self.activation = activation\n",
    "        self.selector = selector\n",
    "        self.dataset = dataset\n",
    "        self.DIR = DIR\n",
    "        self.Synapse = Synapse\n",
    "        self.leak = leak\n",
    "        \n",
    "        if self.Synapse == True:\n",
    "            self.syn_key = 'syn'\n",
    "        else:\n",
    "            self.syn_key = 'nosyn'\n",
    "        \n",
    "    def objective(self):\n",
    "        # Learning rate\n",
    "        \n",
    "        lr_dict = pickle.load(open('./results/hyperparameters/'+self.model_type+'_lr.hyperopt', 'rb'))\n",
    "            \n",
    "        lr = lr_dict[self.activation][self.dataset][self.syn_key]['lr']\n",
    "        \n",
    "        # SQGL parameters if appropriate\n",
    "        atten = 0.5\n",
    "        scale = 1\n",
    "        \n",
    "        # Initialize settings\n",
    "        bs = 256\n",
    "        weighting = 'paired'\n",
    "        trials = 10\n",
    "        epochs = 2000\n",
    "        trees_set = [1, 2, 4, 8, 16, 32]\n",
    "\n",
    "        # Load class-dataset list\n",
    "        classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "        classes = [classes[self.selector]]\n",
    "\n",
    "        # Initialize recording\n",
    "        acc = np.zeros((len(classes), trials, len(trees_set)))\n",
    "        loss = np.zeros((len(classes), trials, len(trees_set)))\n",
    "        \n",
    "        # For each dataset enumerated from classes list\n",
    "        for j, (t1, t2, ds) in enumerate(classes):\n",
    "            print(t1, t2, ds)\n",
    "            # Load data loaders\n",
    "            trainloaders, validloaders, testloader = dataset_weighted_split_all(bs, t1, t2, weighting, trials, ds, permute=False)\n",
    "            # Initialize input size for model initialization purposes\n",
    "            input_size = trainloaders[0].dataset.tensors[0][0].shape[0]\n",
    "            # For each trial\n",
    "            for i in range(trials):\n",
    "                # For each tree number:\n",
    "                for k, trees in enumerate(trees_set):\n",
    "                    print(j, i, k)\n",
    "                    # Initialize the model\n",
    "                    if self.model_type == 'fcnn':\n",
    "                        if self.Synapse == True:\n",
    "                            model = synapse_fcnn(Input_size=input_size, Hidden_size=trees*2, Output_size=1,\n",
    "                                                 Activation=self.activation, learn=False, alpha=1, beta=1, gamma=1, \n",
    "                                                 scale=scale, atten=atten, leak=self.leak).cuda()\n",
    "                        else:\n",
    "                            model = simple_fcnn(Input_size=input_size, Hidden_size=trees*2, Output_size=1,\n",
    "                                                 Activation=self.activation, learn=False, alpha=1, beta=1, gamma=1, \n",
    "                                                 scale=scale, atten=atten, leak=self.leak).cuda()\n",
    "                    else:\n",
    "                        model = ktree_sparse(ds=ds, Repeats=trees, Padded=True, Activation=self.activation, \n",
    "                                             learn=False, alpha=1, beta=1, gamma=1, scale=scale, atten=atten,\n",
    "                                             synapse=self.Synapse).cuda()\n",
    "                    #Train and test ktree, assigning loss and acc values\n",
    "                    loss_curve, acc_curve, loss[j,i,k], acc[j,i,k], model_t = train_test_ktree_sparse(model, trainloaders[i],\n",
    "                                                                                        validloaders[i], testloader, \n",
    "                                                                                        epochs = epochs, randorder=False,\n",
    "                                                                                        lr=lr)\n",
    "                    \n",
    "                    np.save(self.DIR+'acc_'+'_'.join((self.model_type,self.activation,self.syn_key,str(self.leak*100),self.dataset)), acc)\n",
    "                    np.save(self.DIR+'loss_'+'_'.join((self.model_type,self.activation,self.syn_key,str(self.leak*100),self.dataset)), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run nonlinearities for all classes - ktree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='ktree', activation='relu', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=False, leak=0)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='ktree', activation='relu', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=False, leak=0.01)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='ktree', activation='sigmoid', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=False, leak=0)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='ktree', activation='swish', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=False, leak=0)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQGL nosyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='ktree', activation='SQGL', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=False, leak=0)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQGL syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='ktree', activation='SQGL', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=True, leak=0)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run nonlinearities for all classes - FCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='fcnn', activation='relu', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=False, leak=0)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='fcnn', activation='relu', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=False, leak=0.01)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='fcnn', activation='sigmoid', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=False, leak=0)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='fcnn', activation='swish', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=False, leak=0)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQGL nosyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='fcnn', activation='SQGL', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=False, leak=0)\n",
    "    testing_loop.objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQGL syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('./results/classes.npy', allow_pickle=True)\n",
    "classes = classes[:,2]\n",
    "\n",
    "for selector, dataset in enumerate(classes):\n",
    "    testing_loop = Nonlinearities(model_type='fcnn', activation='SQGL', selector=selector, dataset=dataset, \n",
    "                 DIR='./results/20210102/', Synapse=True, leak=0)\n",
    "    testing_loop.objective()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py36_1] *",
   "language": "python",
   "name": "conda-env-.conda-py36_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
